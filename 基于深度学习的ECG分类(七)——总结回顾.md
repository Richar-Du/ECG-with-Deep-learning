---
title: 关于心电项目中数据不平衡的解决方案
author: 都一凡
date: 2020-11-13 09:51:00 +0800
categories: [blog]
tags: [ECG,Deep learning]
image: D:\Myblog\Richar-Du.github.io\assets\img\sample\avatar.jpg
pin: true
---

心电数据不平衡的程度太大了，某些少数类别是正常心跳的几十分之一，用普通的卷积网络做出来效果不是特别好。但是如果通过过采样的方法，数据量极少的类别80%都是生成的，最后结果不太能推广到真实场景。

我的想法是不用过采样的方法，先让数据通过一个自编码器，利用自编码器提取原始数据的特征作为后面的输入，然后用bagging或者boosting的方法训练多个机器学习分类器。这样相当于用上了所有的数据，而且很大程度上减小了数据不平衡的程度。

> 老师的建议：
>
> - 模型表现不好不一定是数据不平衡导致的，还有可能是训练集和测试集的样本分布不均衡。可以采用分层抽样的方法，使得训练集和测试集的样本有相同的分布。
> - 找更多的数据集，把原来数据集中少数类的样本直接删掉，加入新数据集的样本。
> - 按照自己的想法做。boosting和bagging是提升模型性能的通用方法，但是需要一些技巧；而且一个好的自编码器构建起来也比较麻烦。可以放在后期项目完善阶段再深入研究。

**下面就介绍将不同的数据集合并，进而重新训练：**

查找PhysioNet中的心电数据集，最终选择了较为知名的MIT-BIH Arrhythmia Database，Europen ST-T Database，MIT-BIH ST Database，Sudden Cardiac Death Holter Database进行合并。各数据库的信息可以在PhysioNet官网查到，其中不同数据库的采样频率不同，使用的导联方式不同，数据标签不同，在合并时我采用了如下方式：

- 采样频率：通过傅里叶变换的方法将250Hz的数据变成360Hz，使用了python scipy科学计算包中的signal.resample函数。

```python
re_signal = scipy.signal.resample(signal, 3600)
```

因为原始数据是360Hz，切分成10s，因此一段有3600个数据。signal.resample函数把250Hz的数据利用傅里叶方法变成了360Hz。

- 导联方式：此处一直纠结该如何从众多不同的导联方式中选择合适的导联，后来联系了一篇论文的作者，他的解释很简单，但是也很合理：不同的导联是从身体的不同部位测得的电势，会有粗粒度上的一些不同，就像图像数据中的一些边缘特征，可以在卷积神经网络的前几层提取出来，因此不需要手动选择导联。（但是机器学习不同，机器学习只能学习已经提取出的特征与输出之间的联系，不能自动提取特征，因此需要谨慎选择导联方式）

- 数据标签：因为我们合并数据集的目的之一就是平衡数据集，因此自然需要从中选择数量最多的标签。最终综合考虑各个数据库中的标签，我们选择了如下标签作为最终的训练标签。

  ```python
  AAMI=['N','L','R','V','A','|','B']
  ```

最终得到数据的情况如下：

| \|   | N                    | s    | V    | B    | L    | R    | A    |
| ---- | -------------------- | ---- | ---- | ---- | ---- | ---- | ---- |
| 4846 | 85085（其他）+75052（MIT） | 1418 | 8817 | 5140 | 8075 | 7259 | 2546 |

