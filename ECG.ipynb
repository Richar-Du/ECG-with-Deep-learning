{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 心律不齐分类\n",
    "## 1.1 参考资料\n",
    "* Keras：Conv1D：https://blog.csdn.net/VeritasCN/article/details/90050584\n",
    "* 深度学习模型系列(1) | VGG16 Keras实现:https://cloud.tencent.com/developer/article/1509047\n",
    "* ECGAI_1D-CNN:https://github.com/SEU-wzx/ECGAI_1D-CNN\n",
    "* Keras 自编码器AutoEncoder（五）:https://blog.csdn.net/qq_19707521/article/details/78740986\n",
    "* 关于keras模型拆装：https://tensorflow.google.cn/guide/keras/save_and_serialize?hl=zh-cn\n",
    "* SENet：https://www.cnblogs.com/bonelee/p/9030092.html\n",
    "* Keras实现Senet block模块:https://blog.csdn.net/sinat_36618660/article/details/102546146"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, Sequential,load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input,\\\n",
    "BatchNormalization,Multiply,Layer,GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras.activations as activations\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('data/X.csv',delimiter=',')\n",
    "label = np.loadtxt('data/Y.csv',delimiter=',',dtype='int')\n",
    "label = np.eye(7)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [5774 3846 3057 ... 7567 5792 1675] TEST: [1013 1673 2862 ... 6989 8021 1745]\n",
      "X_train :  6624\n",
      "X_test  :  1656\n",
      "shape of X_train :  (3600,)\n",
      "shape of y_train :  (6624, 7)\n",
      "shape of X_test :  (1656, 3600)\n",
      "shape of y_test :  (1656, 7)\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "classes = ['1','2','3','4','5','6','0']\n",
    "ClassesNum = len(classes)\n",
    "        \n",
    "# list -> arr\n",
    "X=np.array(dataset)\n",
    "Y=np.array(label)\n",
    "\n",
    "\n",
    "# 分层抽样\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size=0.8,random_state=0)\n",
    "sss.get_n_splits(X, Y)\n",
    "for train_index, test_index in sss.split(X, Y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "# get X_train, X_test, y_train, y_test \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "# X_train, X_val, y_train,y_val = train_test_split(X_train,y_train,test_size=0.2)\n",
    "\n",
    "print(\"X_train : \", len(X_train))\n",
    "print(\"X_test  : \", len(X_test))\n",
    "print(\"shape of X_train : \", np.shape(X_train[0]))\n",
    "print(\"shape of y_train : \", np.shape(y_train))\n",
    "# print(\"shape of X_val : \", np.shape(X_val))\n",
    "# print(\"shape of y_val : \", np.shape(y_val))\n",
    "print(\"shape of X_test : \", np.shape(X_test))\n",
    "print(\"shape of y_test : \", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 卷积降噪自编码器训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3600, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1 (Conv1D)              (None, 3600, 16)     64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 3600, 16)     64          encoder_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 3600, 16)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2 (MaxPooling1D)        (None, 1800, 16)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 16)           0           encoder_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            64          global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1800, 16)     0           encoder_2[0][0]                  \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1 (Conv1D)              (None, 1800, 8)      392         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_3 (Conv1D)              (None, 1800, 16)     400         decoder_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_4 (UpSampling1D)        (None, 3600, 16)     0           decoder_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_5 (Conv1D)              (None, 3600, 1)      49          decoder_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,097\n",
      "Trainable params: 1,033\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 为原数据加入噪声\n",
    "## 噪声影响程度\n",
    "factor = 0.05\n",
    "np.random.seed(123)\n",
    "noise = np.random.randn(len(X_train),len(X_train[0]))*factor\n",
    "X_train += noise\n",
    "\n",
    "# 定义SEBlock\n",
    "## reduction 用来降维\n",
    "def SEBlock(inputs,reduction=4,if_train=True):\n",
    "    x = GlobalAveragePooling1D()(inputs)\n",
    "    x = Dense(int(x.shape[-1]) // reduction, use_bias=False,activation=activations.relu,trainable=if_train)(x)\n",
    "    x = Dense(int(inputs.shape[-1]), use_bias=False,activation=activations.hard_sigmoid,trainable=if_train)(x)\n",
    "    return Multiply()([inputs,x])\n",
    "\n",
    "\n",
    "# 定义卷积降噪自编码器\n",
    "def conv_autoencoder(input_ecg):\n",
    "    x = layers.Conv1D(filters = 16, kernel_size = 3,padding='same',name='encoder_1')(input_ecg)\n",
    "    x = BatchNormalization(trainable=False)(x)\n",
    "    x = Activation('relu')(x)  \n",
    "    x = layers.MaxPool1D(pool_size = 2, padding='same',name='encoder_2')(x)\n",
    "    encoded = SEBlock(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters = 8, kernel_size = 3, activation='relu', padding='same',name='decoder_1')(encoded)\n",
    "    x = layers.Conv1D(filters = 16, kernel_size = 3, activation='relu', padding='same',name='decoder_3')(x)\n",
    "    x = layers.UpSampling1D(size = 2,name='decoder_4')(x)  \n",
    "    decoded = layers.Conv1D(filters = 1, kernel_size = 3, activation='sigmoid', padding='same',name='decoder_5')(x)\n",
    "\n",
    "    autoencoder = Model(inputs=input_ecg, outputs=decoded)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "input_ecg = Input(shape=(3600,1))\n",
    "autoencoder = conv_autoencoder(input_ecg = input_ecg)\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.reshape(X_test, (np.shape(X_test)[0], np.shape(X_test)[1], 1))\n",
    "# 训练降噪自编码器\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')  \n",
    "  \n",
    "# 打开一个终端并启动TensorBoard，终端中输入 tensorboard --logdir=/autoencoder  \n",
    "# autoencoder.fit(X_train, X_train, epochs=2, batch_size=32,  shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 混合模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载降噪自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19_heart(input_data,classes=7):\n",
    "    \n",
    "    x = layers.Conv1D(filters = 128, kernel_size = 3,padding='same',name='encoder_1')(input_ecg)\n",
    "    x = BatchNormalization(trainable=False)(x)\n",
    "    x = Activation('relu')(x)  \n",
    "    x = layers.MaxPool1D(pool_size = 2, padding='same',name='encoder_2')(x)\n",
    "    x = SEBlock(x)\n",
    "    x = layers.Conv1D(filters = 64, kernel_size = 3,padding='same',name='encoder_3')(x)\n",
    "    x = BatchNormalization(trainable=False)(x)\n",
    "    x = Activation('relu')(x)  \n",
    "    x = layers.MaxPool1D(pool_size = 2, padding='same',name='encoder_4')(x)\n",
    "    x = SEBlock(x)\n",
    "    \n",
    "    # Block2\n",
    "    x = layers.Conv1D(filters = 64,kernel_size = 3,padding='same',name='block2_conv1',activation='relu')(x)\n",
    "    x = layers.Conv1D(filters = 64,kernel_size = 3,padding='same',name='block2_conv2',activation='relu')(x)\n",
    "    x = SEBlock(x)\n",
    "    x = layers.MaxPool1D(pool_size=2,strides=2,name='block2_pool')(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters = 128,kernel_size = 3,padding='same',name='block3_conv1',activation='relu')(x)\n",
    "    x = layers.MaxPool1D(pool_size=2,strides=2,name='block3_pool_1')(x)\n",
    "    x = layers.Conv1D(filters = 128,kernel_size = 3,padding='same',name='block3_conv2',activation='relu')(x)\n",
    "    x = layers.MaxPool1D(pool_size=2,strides=2,name='block3_pool_2')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    model = Model(input_data,x,name='VGG19-Heart')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG19-Heart\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3600, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1 (Conv1D)              (None, 3600, 128)    512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 3600, 128)    512         encoder_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 3600, 128)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2 (MaxPooling1D)        (None, 1800, 128)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           encoder_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 32)           4096        global_average_pooling1d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          4096        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1800, 128)    0           encoder_2[0][0]                  \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_3 (Conv1D)              (None, 1800, 64)     24640       multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1800, 64)     256         encoder_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1800, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_4 (MaxPooling1D)        (None, 900, 64)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 64)           0           encoder_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           1024        global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 900, 64)      0           encoder_4[0][0]                  \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv1D)           (None, 900, 64)      12352       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv1D)           (None, 900, 64)      12352       block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 64)           0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 16)           1024        global_average_pooling1d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 64)           1024        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 900, 64)      0           block2_conv2[0][0]               \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling1D)      (None, 450, 64)      0           multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv1D)           (None, 450, 128)     24704       block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_1 (MaxPooling1D)    (None, 225, 128)     0           block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv1D)           (None, 225, 128)     49280       block3_pool_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_2 (MaxPooling1D)    (None, 112, 128)     0           block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 112, 128)     0           block3_pool_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 14336)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 7)            100359      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 237,255\n",
      "Trainable params: 236,487\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = vgg19_heart(input_data=input_ecg,classes=ClassesNum)\n",
    "print(model.summary())\n",
    "# for i in range(1,9):\n",
    "#     model.layers[i].set_weights(autoencoder.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6624, 3600, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setting optimizers & compile\n",
    "optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)\n",
    "# model_all.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# expand X_train dims\n",
    "# Y : int -> binary (one-hot)\n",
    "# y_train = to_categorical(y_train,num_classes = ClassesNum)\n",
    "# y_test = to_categorical(y_test,num_classes = ClassesNum)\n",
    "\n",
    "display(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "332/332 [==============================] - 115s 348ms/step - loss: 0.9681 - accuracy: 0.7390 - val_loss: 0.8038 - val_accuracy: 0.7313\n",
      "Epoch 2/100\n",
      "332/332 [==============================] - 126s 381ms/step - loss: 0.6401 - accuracy: 0.7992 - val_loss: 0.4906 - val_accuracy: 0.8611\n",
      "Epoch 3/100\n",
      "332/332 [==============================] - 126s 380ms/step - loss: 0.4066 - accuracy: 0.8817 - val_loss: 0.4164 - val_accuracy: 0.8898\n",
      "Epoch 4/100\n",
      "332/332 [==============================] - 123s 370ms/step - loss: 0.3030 - accuracy: 0.9053 - val_loss: 0.3753 - val_accuracy: 0.9034\n",
      "Epoch 5/100\n",
      "332/332 [==============================] - 129s 389ms/step - loss: 0.2425 - accuracy: 0.9239 - val_loss: 0.4021 - val_accuracy: 0.9094\n",
      "Epoch 6/100\n",
      "332/332 [==============================] - 121s 364ms/step - loss: 0.1913 - accuracy: 0.9358 - val_loss: 0.4141 - val_accuracy: 0.9034\n",
      "Epoch 7/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.1508 - accuracy: 0.9513 - val_loss: 0.4380 - val_accuracy: 0.9049\n",
      "Epoch 8/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.1203 - accuracy: 0.9583 - val_loss: 0.6179 - val_accuracy: 0.9011\n",
      "Epoch 9/100\n",
      "332/332 [==============================] - 120s 362ms/step - loss: 0.0897 - accuracy: 0.9696 - val_loss: 0.6062 - val_accuracy: 0.8913\n",
      "Epoch 10/100\n",
      "332/332 [==============================] - 122s 368ms/step - loss: 0.0998 - accuracy: 0.9681 - val_loss: 0.4485 - val_accuracy: 0.9019\n",
      "Epoch 11/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0784 - accuracy: 0.9732 - val_loss: 0.4611 - val_accuracy: 0.9147\n",
      "Epoch 12/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0646 - accuracy: 0.9787 - val_loss: 0.5923 - val_accuracy: 0.9117\n",
      "Epoch 13/100\n",
      "332/332 [==============================] - 120s 362ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.5592 - val_accuracy: 0.9132\n",
      "Epoch 14/100\n",
      "332/332 [==============================] - 122s 368ms/step - loss: 0.0457 - accuracy: 0.9849 - val_loss: 0.6844 - val_accuracy: 0.9155\n",
      "Epoch 15/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0553 - accuracy: 0.9828 - val_loss: 0.6172 - val_accuracy: 0.9147\n",
      "Epoch 16/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0480 - accuracy: 0.9832 - val_loss: 0.6636 - val_accuracy: 0.9087\n",
      "Epoch 17/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.9021 - val_accuracy: 0.9177\n",
      "Epoch 18/100\n",
      "332/332 [==============================] - 121s 364ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.6188 - val_accuracy: 0.9192\n",
      "Epoch 19/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0467 - accuracy: 0.9849 - val_loss: 0.6774 - val_accuracy: 0.9109\n",
      "Epoch 20/100\n",
      "332/332 [==============================] - 122s 366ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.7458 - val_accuracy: 0.9147\n",
      "Epoch 21/100\n",
      "332/332 [==============================] - 129s 388ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 0.7569 - val_accuracy: 0.9125\n",
      "Epoch 22/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0420 - accuracy: 0.9843 - val_loss: 0.6609 - val_accuracy: 0.9132\n",
      "Epoch 23/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.8396 - val_accuracy: 0.9132\n",
      "Epoch 24/100\n",
      "332/332 [==============================] - 124s 373ms/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 0.7454 - val_accuracy: 0.9064\n",
      "Epoch 25/100\n",
      "332/332 [==============================] - 122s 367ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.8078 - val_accuracy: 0.9275\n",
      "Epoch 26/100\n",
      "332/332 [==============================] - 121s 364ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.8078 - val_accuracy: 0.9215\n",
      "Epoch 27/100\n",
      "332/332 [==============================] - 122s 367ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 0.7955 - val_accuracy: 0.9200\n",
      "Epoch 28/100\n",
      "332/332 [==============================] - 123s 370ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.8260 - val_accuracy: 0.9200\n",
      "Epoch 29/100\n",
      "332/332 [==============================] - 122s 369ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.8251 - val_accuracy: 0.9275\n",
      "Epoch 30/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0215 - accuracy: 0.9917 - val_loss: 1.0043 - val_accuracy: 0.9147\n",
      "Epoch 31/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.0383 - accuracy: 0.9868 - val_loss: 0.8452 - val_accuracy: 0.9260\n",
      "Epoch 32/100\n",
      "332/332 [==============================] - 122s 367ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.8574 - val_accuracy: 0.9200\n",
      "Epoch 33/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.8696 - val_accuracy: 0.9253\n",
      "Epoch 34/100\n",
      "332/332 [==============================] - 123s 371ms/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.8356 - val_accuracy: 0.9215\n",
      "Epoch 35/100\n",
      "332/332 [==============================] - 128s 385ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.9556 - val_accuracy: 0.9208\n",
      "Epoch 36/100\n",
      "332/332 [==============================] - 125s 375ms/step - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.8679 - val_accuracy: 0.9162\n",
      "Epoch 37/100\n",
      "332/332 [==============================] - 123s 370ms/step - loss: 0.0236 - accuracy: 0.9911 - val_loss: 0.9211 - val_accuracy: 0.9238\n",
      "Epoch 38/100\n",
      "332/332 [==============================] - 122s 366ms/step - loss: 0.0198 - accuracy: 0.9934 - val_loss: 0.7419 - val_accuracy: 0.9072\n",
      "Epoch 39/100\n",
      "332/332 [==============================] - 124s 372ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.8860 - val_accuracy: 0.9192\n",
      "Epoch 40/100\n",
      "332/332 [==============================] - 123s 371ms/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.7256 - val_accuracy: 0.9170\n",
      "Epoch 41/100\n",
      "332/332 [==============================] - 123s 370ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.7984 - val_accuracy: 0.9192\n",
      "Epoch 42/100\n",
      "332/332 [==============================] - 122s 369ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.8025 - val_accuracy: 0.9185\n",
      "Epoch 43/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0128 - accuracy: 0.9947 - val_loss: 0.9349 - val_accuracy: 0.9260\n",
      "Epoch 44/100\n",
      "332/332 [==============================] - 122s 366ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.8723 - val_accuracy: 0.9268\n",
      "Epoch 45/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 1.0490 - val_accuracy: 0.9230\n",
      "Epoch 46/100\n",
      "332/332 [==============================] - 122s 368ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.7239 - val_accuracy: 0.9208\n",
      "Epoch 47/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.8852 - val_accuracy: 0.9170\n",
      "Epoch 48/100\n",
      "332/332 [==============================] - 121s 363ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.7353 - val_accuracy: 0.9170\n",
      "Epoch 49/100\n",
      "332/332 [==============================] - 122s 368ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.8059 - val_accuracy: 0.9155\n",
      "Epoch 50/100\n",
      "332/332 [==============================] - 121s 364ms/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 1.1342 - val_accuracy: 0.9155\n",
      "Epoch 51/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.9312 - val_accuracy: 0.9245\n",
      "Epoch 52/100\n",
      "332/332 [==============================] - 122s 366ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.8747 - val_accuracy: 0.9140\n",
      "Epoch 53/100\n",
      "332/332 [==============================] - 121s 366ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.9959 - val_accuracy: 0.9200\n",
      "Epoch 54/100\n",
      "332/332 [==============================] - 123s 371ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.8903 - val_accuracy: 0.9230\n",
      "Epoch 55/100\n",
      "332/332 [==============================] - 122s 366ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.9034 - val_accuracy: 0.9238\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - 122s 367ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.9525 - val_accuracy: 0.9140\n",
      "Epoch 57/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 1.1537 - val_accuracy: 0.9208\n",
      "Epoch 58/100\n",
      "332/332 [==============================] - 121s 365ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.9119 - val_accuracy: 0.9200\n",
      "Epoch 59/100\n",
      "332/332 [==============================] - 123s 369ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 1.0476 - val_accuracy: 0.9200\n",
      "Epoch 60/100\n",
      " 56/332 [====>.........................] - ETA: 1:48 - loss: 0.0213 - accuracy: 0.9944"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-63087c2f255a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# history = model_all.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\treo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "# history = model_all.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS)\n",
    "history = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - 2s 10ms/step - loss: 0.4967 - accuracy: 0.9079\n",
      "loss of val :  0.4967125654220581\n",
      "acc of val :  0.9079245328903198\n"
     ]
    }
   ],
   "source": [
    "# val_loss_acc = model_all.evaluate(X_test, y_test, batch_size=100)\n",
    "val_loss_acc = model.evaluate(X_test, y_test, batch_size = 16)\n",
    "print(\"loss of val : \", val_loss_acc[0])\n",
    "print(\"acc of val : \", val_loss_acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.0328348e-03 9.9301237e-01 9.4439543e-04 ... 1.0297632e-05\n",
      "  1.4912478e-12 7.1791355e-08]\n",
      " [1.7696004e-07 9.9868613e-01 1.7616973e-04 ... 1.1261554e-03\n",
      "  1.0670851e-05 2.7295914e-07]\n",
      " [3.8413259e-06 2.0688849e-03 2.3894283e-05 ... 2.3359444e-08\n",
      "  9.9790335e-01 2.8905253e-16]\n",
      " ...\n",
      " [2.6814723e-06 9.0382707e-01 6.3994676e-03 ... 8.9705147e-02\n",
      "  3.1953929e-05 2.5532612e-05]\n",
      " [1.6886381e-03 9.9400842e-01 2.5240013e-03 ... 1.7757314e-03\n",
      "  4.8706870e-08 3.1829595e-06]\n",
      " [1.7659280e-08 9.9972790e-01 1.2425847e-05 ... 1.6486937e-04\n",
      "  9.1883332e-05 3.9440572e-08]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pre = np.zeros((int(predictions.size/predictions[0].size),predictions[0].size))\n",
    "for i in range(len(predictions)):\n",
    "    y_pre[i][np.where(predictions[i]==max(predictions[i]))[0][0]]=1\n",
    "print(y_pre[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.jet):\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, '{:.2f}'.format(cm[i, j]), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "# 显示混淆矩阵\n",
    "def plot_confuse(model, x_val, y_val):\n",
    "    predictions = model.predict(x_val)\n",
    "    truelabel = y_val.argmax(axis=-1)   # 将one-hot转化为label\n",
    "    conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(conf_mat, range(np.max(truelabel)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre_label = y_pre.argmax(axis=-1)\n",
    "test_label = y_test.argmax(axis=-1)\n",
    "conf_mat = confusion_matrix(y_true=test_label,y_pred=pre_label)\n",
    "sns.heatmap(conf_mat,annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
